schema cord19 {
    document cord19 {
        field cord_uid type string {
            indexing: attribute | summary
        }
        field title type string {
            indexing: index | summary
            index: enable-bm25
        }
        field title_token_ids type tensor<float>(d0[64]) {
            indexing: summary | attribute
        }

    }
    fieldset default {
        fields: title
    }
    rank-profile default {
        first-phase {
            expression: nativeRank(title)
        }
    }

    rank-profile bm25 {
        first-phase {
            expression: bm25(title)
        }
    }

    onnx-model bert {
        file: files/bert.onnx
        input  input_ids: input_ids
        input  token_type_ids: token_type_ids
        input  attention_mask: attention_mask
        output logits: logits
    }


    rank-profile bert {
        constants {
          TOKEN_NONE: 0
          TOKEN_CLS:  101
          TOKEN_SEP:  102
        }

        # Find length of question input
        function question_length() {
            expression: sum(map(query(query_token_ids), f(a)(a > 0)))
        }

        # Find length of the title
        function title_length() {
            expression: sum(map(attribute(title_token_ids), f(a)(a > 0)))
        }

        # Create input sequence: CLS + query + SEP + title + 0's
        function input_ids() {
          expression {
            tensor<float>(d0[1],d1[128])(
               if (d1 == 0,
                 TOKEN_CLS,
               if (d1 < question_length + 1,
                 query(query_token_ids){d0:(d1-1)},
               if (d1 == question_length + 1,
                 TOKEN_SEP,
               if (d1 < question_length + title_length + 2,
                 attribute(title_token_ids){d0:(d1-question_length-2)},
               if (d1 == question_length + title_length + 2,
                  TOKEN_SEP,
                  TOKEN_NONE
               ))))))
          }
        }

        # The attention mask has 1's for every token that is set
        function attention_mask() {
          expression: map(input_ids, f(a)(a > 0))
        }

        # Create token_type_ids: 0 for query and 1 for doc
        function token_type_ids() {
          expression {
            tensor<float>(d0[1],d1[128])(
               if (d1 < question_length,
                 0,
               if (d1 < question_length + title_length,
                 1,
                 TOKEN_NONE
               )))
          }
        }

        first-phase {
          expression: bm25(title)
        }

        function eval() {
          expression:tensor(x{}):{x1:onnxModel(bert).logits{d0:0,d1:0}}
        }

        second-phase {
          rerank-count: 10
          expression: sum(eval)
        }

        summary-features {
          onnxModel(bert).logits
          eval
          input_ids
          attention_mask
          token_type_ids
        }

    }

}